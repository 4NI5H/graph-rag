{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJZxGk0cTe34qcMfZZJAIL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4NI5H/graph-rag/blob/main/graph_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nFQ6Ja6bmkr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698099c1-4cd9-469a-89b0-1dd16c7f564d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aY-GvXCAdkCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "os.environ[\"NEO4J_URI\"] = userdata.get('NEO4J_URI')\n",
        "os.environ[\"NEO4J_USERNAME\"] = userdata.get('NEO4J_USERNAME')\n",
        "os.environ[\"NEO4J_PASSWORD\"] = userdata.get('NEO4J_PASSWORD')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "graph = Neo4jGraph()"
      ],
      "metadata": {
        "id": "nRm7mz18stwZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNXwdlSpdM5S",
        "outputId": "cb823346-2a56-487a-fd1c-726ace50c163"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x7e210a32bdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)"
      ],
      "metadata": {
        "id": "PGGCkkWCdlBG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "text = \"\"\"\n",
        "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
        "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
        "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
        "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
        "\"\"\"\n",
        "documents = [Document(page_content=text)]\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents[0].relationships}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnBMQOtMeMXt",
        "outputId": "91e949ad-33bd-4ae4-bcbe-28ae49a3611a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Institution', properties={}), Node(id='Nobel Prize', type='Award', properties={}), Node(id='Radioactivity', type='Concept', properties={})]\n",
            "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Radioactivity', type='Concept', properties={}), type='RESEARCH_ON', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WINNER', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Pierre Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WINNER', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Institution', properties={}), type='PROFESSOR', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WINNER', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WINNER', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WINNER', properties={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_transformer_props = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
        "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
        "    node_properties=[\"born_year\"],\n",
        ")\n",
        "graph_documents_props = llm_transformer_props.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents_props[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents_props[0].relationships}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yXD4S_kfF49",
        "outputId": "5d38f284-5ce7-4877-dd6b-f2cfc996f5df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes:[Node(id='Marie Curie', type='Person', properties={'born_year': '1867'}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='Poland', type='Country', properties={}), Node(id='France', type='Country', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\n",
            "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Poland', type='Country', properties={}), type='NATIONALITY', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='France', type='Country', properties={}), type='NATIONALITY', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='WORKED_AT', properties={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_graph_documents(graph_documents_props)"
      ],
      "metadata": {
        "id": "myvOelWPfJ-4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.refresh_schema()\n",
        "print(graph.schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRGlNGHwiH_o",
        "outputId": "06193748-2f60-4bee-a67e-7818ad1d7eb6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties:\n",
            "Person {id: STRING, born_year: STRING, name: STRING}\n",
            "Country {id: STRING}\n",
            "Organization {id: STRING}\n",
            "Movie {id: STRING, released: DATE, title: STRING, imdbRating: FLOAT}\n",
            "Genre {name: STRING}\n",
            "Relationship properties:\n",
            "\n",
            "The relationships:\n",
            "(:Person)-[:NATIONALITY]->(:Country)\n",
            "(:Person)-[:SPOUSE]->(:Person)\n",
            "(:Person)-[:WORKED_AT]->(:Organization)\n",
            "(:Person)-[:DIRECTED]->(:Movie)\n",
            "(:Person)-[:ACTED_IN]->(:Movie)\n",
            "(:Movie)-[:IN_GENRE]->(:Genre)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_query=\"\"\"\n",
        "LOAD CSV WITH HEADERS FROM\n",
        "'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' as row\n",
        "\n",
        "MERGE(m:Movie{id:row.movieId})\n",
        "SET m.released = date(row.released),\n",
        "    m.title = row.title,\n",
        "    m.imdbRating = toFloat(row.imdbRating)\n",
        "FOREACH (director in split(row.director, '|') |\n",
        "    MERGE (p:Person {name:trim(director)})\n",
        "    MERGE (p)-[:DIRECTED]->(m))\n",
        "FOREACH (actor in split(row.actors, '|') |\n",
        "    MERGE (p:Person {name:trim(actor)})\n",
        "    MERGE (p)-[:ACTED_IN]->(m))\n",
        "FOREACH (genre in split(row.genres, '|') |\n",
        "    MERGE (g:Genre {name:trim(genre)})\n",
        "    MERGE (m)-[:IN_GENRE]->(g))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FS53lbSQgAPt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.query(movie_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOjkxWAugIFH",
        "outputId": "e180b521-15ed-4856-c954-9faf40b2b888"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import GraphCypherQAChain\n",
        "chain=GraphCypherQAChain.from_llm(llm=llm,graph=graph,verbose=True,allow_dangerous_requests=True)\n",
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWDpRbkShOEJ",
        "outputId": "c8f8f349-fb3e-4663-b980-74f65407c339"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphCypherQAChain(verbose=True, graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x7e210a32bdc0>, cypher_generation_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7e2145d63f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7e2109573d60>, root_client=<openai.OpenAI object at 0x7e2109e19570>, root_async_client=<openai.AsyncOpenAI object at 0x7e2145d63fa0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), qa_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nHere is an example:\\n\\nQuestion: Which managers own Neo4j stocks?\\nContext:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\\nHelpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\\n\\nFollow this example when generating answers.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7e2145d63f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7e2109573d60>, root_client=<openai.OpenAI object at 0x7e2109e19570>, root_async_client=<openai.AsyncOpenAI object at 0x7e2145d63fa0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), graph_schema='Node properties are the following:\\nPerson {id: STRING, born_year: STRING, name: STRING},Country {id: STRING},Organization {id: STRING},Movie {id: STRING, released: DATE, title: STRING, imdbRating: FLOAT},Genre {name: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Person)-[:NATIONALITY]->(:Country),(:Person)-[:SPOUSE]->(:Person),(:Person)-[:WORKED_AT]->(:Organization),(:Person)-[:DIRECTED]->(:Movie),(:Person)-[:ACTED_IN]->(:Movie),(:Movie)-[:IN_GENRE]->(:Genre)', allow_dangerous_requests=True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=chain.invoke({\"query\":\"Who was the director of the moview Tom and Huck\"})\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy6nmb3NhiRj",
        "outputId": "07898c3c-f25f-4dd0-e9d2-f43a19474189"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (p:Person)-[:DIRECTED]->(m:Movie {title: 'Tom and Huck'}) RETURN p.name\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'p.name': 'Peter Hewitt'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Who was the director of the moview Tom and Huck',\n",
              " 'result': 'Peter Hewitt was the director of the movie Tom and Huck.'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}